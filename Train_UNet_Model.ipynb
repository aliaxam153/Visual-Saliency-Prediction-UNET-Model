{"cells":[{"cell_type":"markdown","metadata":{"id":"vHNXE8UW770O"},"source":["**UNET- Semantic Segmentation Model Training Implementation**"]},{"cell_type":"markdown","metadata":{"id":"ftd9fn5T8DgB"},"source":["**Step 1:** Configure Dataset Filepaths & Load functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68333,"status":"ok","timestamp":1702835664503,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"Xae73yfUjVVv","outputId":"ffb2ea0a-e7c0-4132-9c9e-1146da2cc8da"},"outputs":[],"source":["import os\n","import glob\n","\n","# Replace the \"home/username/dev/\" with your own directory path\n","work_dir= \"/home/aazam/dev\" + \"/Visual-Saliency-Prediction-UNET-Model/\"\n","# Verify image paths\n","if not os.path.exists(work_dir):\n","    print(f\"Path does not exist: {work_dir}\")\n","else:\n","    print(f\"Path exists: {work_dir}\")\n","\n","    # Create lists of image and mask file paths\n","    image_paths = glob.glob(work_dir + 'Dataset/Images/*.png')\n","    mask_paths = glob.glob(work_dir + 'Dataset/Masks/*.png')\n","    print('Total Images in Dataset:', len(image_paths))\n","\n","    # Misc Paths\n","    pretrain_modelpath = work_dir + \"Pre-trained_Model/\"\n","    logpath = work_dir + 'Logs'\n","    os.makedirs(pretrain_modelpath, exist_ok=True)\n","    os.makedirs(logpath, exist_ok=True)\n","\n","    # Create new name for Model which will be trained\n","    modelpath = pretrain_modelpath + 'unetmodel_v'+str(len(glob.glob(pretrain_modelpath + '/*.keras')))+'.keras'\n","\n","# Resizing images is optional, since dataset image size is 256x256x3\n","SIZE_X = 128\n","SIZE_Y = 128\n","n_classes = 1  # Number of classes for segmentation\n","# Define your parameters\n","batch_size = 32\n","epochs = 20\n","num_data = len(image_paths)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" # Indicates that TensorFlow's Keras API  will be used for training\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n","\n","import tensorflow as tf\n","from segmentation_models import Unet\n","from segmentation_models.losses import bce_jaccard_loss\n","from segmentation_models.metrics import iou_score\n","\n","# GPU configuration\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            # tf.config.experimental.set_memory_growth(gpu, True)\n","        # tf.config.experimental.set_virtual_device_configuration(gpus[0], \n","        #     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])  # Adjust memory limit as necessary\n","        \n","            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","else:\n","    print(\"No GPUs found. Please check your TensorFlow installation and GPU setup.\")\n","\n","# Define the dataset loading and preprocessing function\n","def preprocess_stage(image_path, mask_path):\n","    # Load and preprocess image\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, (SIZE_X, SIZE_Y))\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","\n","    # Load and preprocess mask\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    mask = tf.image.resize(mask, (SIZE_X, SIZE_Y))\n","    mask = tf.math.round(mask / 255.0)\n","\n","    return image, mask\n","\n","# Adopted U-Net model architecture from \"segmentation_models\" library\n","# Utilized ResNet34 as the backbone, used initial weights from pretrained network ImageNet (Transfer Learning)\n","def unet_model(input_shape):\n","    model = Unet(backbone_name='resnet34', input_shape=input_shape, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    model.compile(optimizer='adam', loss=bce_jaccard_loss, metrics=[iou_score])\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["**Step 2:** Prepare & Split datasets to three batches sets (Training Set, Validation Set & Testing Set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate the number of samples in each set\n","train_split = 0.6\n","validate_split = 0.2\n","test_split = 1-(train_split + validate_split)\n","\n","num_train = int(train_split * num_data)\n","num_valid = int(validate_split * num_data)\n","\n","# Convert your lists into TensorFlow Datasets\n","dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n","\n","# Shuffle the dataset\n","dataset = dataset.shuffle(len(image_paths), seed=42)\n","\n","# Split the dataset\n","dataset_train = dataset.take(num_train)\n","dataset_remaining = dataset.skip(num_train)\n","dataset_valid = dataset_remaining.take(num_valid)\n","dataset_test = dataset_remaining.skip(num_valid)\n","\n","print('Load Dataset and prepare for training:')\n","print(f\"Total Dataset Images: {num_data}\",\n","      f\"\\nTrain Split Images ({round(train_split*100)}%) : {len(dataset_train)}\",\n","      f\"\\nValidate Split Images ({round(validate_split*100)}%) : {len(dataset_valid)}\",\n","      f\"\\nTest Split Images ({round(test_split*100)}%) : {len(dataset_test)}\"\n","      )\n","\n","# Apply your loading and preprocessing function\n","dataset_train = dataset_train.map(preprocess_stage)\n","dataset_valid = dataset_valid.map(preprocess_stage)\n","dataset_test = dataset_test.map(preprocess_stage)\n","\n","# Batch the data\n","dataset_train = dataset_train.batch(batch_size)\n","dataset_valid = dataset_valid.batch(batch_size)\n","dataset_test = dataset_test.batch(batch_size)\n","\n","# Prefetch for performance\n","dataset_train = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n","dataset_valid = dataset_valid.prefetch(buffer_size=tf.data.AUTOTUNE)\n","dataset_test = dataset_test.prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["**Step 3:** Train & Validate the Unet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":797018,"status":"ok","timestamp":1702823042360,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"fuENlaI1jVVy","outputId":"0668de73-9f8a-4968-e25c-b92bd28d87cb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tensorflow import keras\n","\n","# Define model\n","input_shape = (SIZE_X, SIZE_Y, 3)  # Adjust based on the size of your images\n","model = unet_model(input_shape)\n","\n","# Model Checkpoint - save model after every epochs\n","# Save Best only - latest best model will not be overwritten\n","checkpointer = tf.keras.callbacks.ModelCheckpoint(modelpath,verbose=1,save_best_only=True)\n","\n","# Early Stopping - TensorBoard Callbacks\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss'),\n","    tf.keras.callbacks.TensorBoard(log_dir= logpath),\n","    checkpointer\n","]\n","\n","# Train the model\n","history = model.fit(dataset_train, \n","                    validation_data = dataset_valid, \n","                    epochs = epochs, \n","                    callbacks = callbacks)\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['iou_score'], label='Training IoU')\n","plt.plot(history.history['val_iou_score'], label='Validation IoU')\n","plt.title('Training and Validation IoU')\n","plt.xlabel('Epoch')\n","plt.ylabel('IoU')\n","plt.legend()\n","# Plot training and validation loss\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","print(f\"Trained Model has been stored:{modelpath}\")"]},{"cell_type":"markdown","metadata":{"id":"tRRn_scQub2a"},"source":["**Step 4:** Perform Test on the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import keras\n","import matplotlib.pyplot as plt\n","\n","# Load the model\n","model = keras.models.load_model(modelpath, compile=False)\n","\n","# Function to create a mask from predicted values\n","def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask[0]\n","\n","def reverse_preprocess(image):\n","    # Convert from [0, 1] range to [0, 255] range\n","    image = image * 255.0\n","    # Convert image data type from float32 to uint8\n","    image = tf.cast(image, tf.uint8)\n","    \n","    return image\n","\n","rows = 5\n","batch_size = 1  # Assuming you want to visualize one image at a time\n","num_samples = rows  # Number of samples to visualize\n","\n","# Set up the subplots\n","fig, axs = plt.subplots(num_samples, 3, figsize=(9, num_samples * 3))\n","\n","# Extract the desired number of samples\n","dataset_samples = dataset_test.take(num_samples)\n","\n","for i, (image_batch, mask_batch) in enumerate(dataset_samples):\n","    image = image_batch[0]  # Get the first image in the batch\n","    mask = mask_batch[0]  # Get the first mask in the batch\n","\n","    # Expand dimensions if needed for the model input\n","    image_expanded = tf.expand_dims(image, axis=0)\n","    # Predict the mask\n","    pred_mask = model.predict(image_expanded)\n","    pred_mask_np = create_mask(pred_mask).numpy()\n","    # Process the image and mask for display\n","    img = reverse_preprocess(image).numpy()\n","    mask = mask.numpy()\n","\n","    axs[i, 0].imshow(img)\n","    axs[i, 0].set_title(f'Image {i + 1}')\n","    axs[i, 0].axis('off')\n","    axs[i, 1].imshow(mask[..., 0], cmap='gray')\n","    axs[i, 1].set_title('Ground Truth Mask')\n","    axs[i, 1].axis('off')\n","    axs[i, 2].imshow(pred_mask_np, cmap='gray')\n","    axs[i, 2].set_title('Predicted Mask')\n","    axs[i, 2].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":24502,"status":"ok","timestamp":1702835945969,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"OMjAngEk0rTs","outputId":"93e8f80b-6d7d-4442-9483-b00d19ba5981"},"outputs":[],"source":["# Load the trained model\n","model_path = modelpath  # Specify the actual model path\n","model = keras.models.load_model(model_path, compile=False)\n","\n","# Function to create a mask from predicted values\n","def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask[0]\n","\n","def reverse_preprocess(image):\n","    image = image * 255.0\n","    image = tf.cast(image, tf.uint8)\n","    return image\n","\n","# Visualization\n","rows = 5  # Number of images to visualize\n","dataset_samples = dataset_test.unbatch().take(rows)  # Unbatch and take samples\n","\n","fig, axs = plt.subplots(rows, 3, figsize=(9, rows * 3))\n","\n","for i, (image, mask) in enumerate(dataset_samples):\n","    # Expand dimensions for model input\n","    image_expanded = tf.expand_dims(image, axis=0)\n","    pred_mask = model.predict(image_expanded)\n","    pred_mask_np = create_mask(pred_mask).numpy()\n","    \n","    img = reverse_preprocess(image).numpy()\n","    mask = mask.numpy()\n","\n","    axs[i, 0].imshow(img)\n","    axs[i, 0].set_title(f'Image {i + 1}')\n","    axs[i, 0].axis('off')\n","    axs[i, 1].imshow(mask[..., 0], cmap='gray')\n","    axs[i, 1].set_title('Ground Truth Mask')\n","    axs[i, 1].axis('off')\n","    axs[i, 2].imshow(pred_mask_np, cmap='gray')\n","    axs[i, 2].set_title('Predicted Mask')\n","    axs[i, 2].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278048,"status":"ok","timestamp":1702832411604,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"n8jiGe08eqOH","outputId":"d34ff251-d37d-4b76-e217-48e938147cf6"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# Function to create a confusion matrix\n","def create_confusion_matrix(model, dataset):\n","    true_labels = []\n","    predicted_labels = []\n","    for images, masks, _ in dataset:\n","        # Get model predictions\n","        predictions = model.predict(images)\n","        # Append flattened masks and predictions to the lists\n","        true_labels.append(tf.reshape(masks, [-1]).numpy())\n","        predicted_labels.append(tf.reshape(predictions, [-1]).numpy())\n","    # Concatenate the lists to create NumPy arrays\n","    true_labels = np.concatenate(true_labels)\n","    predicted_labels = np.concatenate(predicted_labels)\n","    # Use vectorized operations to create confusion matrix\n","    threshold = 0.5\n","    true_labels_binary = (true_labels > threshold).astype(int)\n","    predicted_labels_binary = (predicted_labels > threshold).astype(int)\n","    cm = confusion_matrix(true_labels_binary, predicted_labels_binary)\n","    return cm\n","# Get confusion matrix for dataset_test\n","confusion_mat = create_confusion_matrix(model, dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"executionInfo":{"elapsed":1167,"status":"ok","timestamp":1702833635880,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"PVf9XCJUiKck","outputId":"c6d0e17e-a683-4e8f-997c-1668f48f9202"},"outputs":[],"source":["# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n","# Extract true positives, true negatives, false positives, and false negatives from the confusion matrix\n","tn, fp, fn, tp = confusion_mat.ravel()\n","# Calculate metrics\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","precision = tp / (tp + fp) if (tp + fp) > 0 else 0  # To avoid division by zero\n","recall = tp / (tp + fn) if (tp + fn) > 0 else 0  # To avoid division by zero\n","f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # To avoid division by zero\n","print('\\nTrained Model Results:')\n","print(f\"Accuracy: {round(accuracy*100)}%\")\n","print(f\"Precision:  {round(precision*100)}%\")\n","print(f\"Recall:  {round(recall*100)}%\")\n","print(f\"F1 Score: {round(f1*100)}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
