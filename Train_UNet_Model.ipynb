{"cells":[{"cell_type":"markdown","metadata":{"id":"vHNXE8UW770O"},"source":["**UNET- Semantic Segmentation Model Training Implementation**"]},{"cell_type":"markdown","metadata":{"id":"ftd9fn5T8DgB"},"source":["**Step 1:** Configure Dataset Filepaths & Load functions"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68333,"status":"ok","timestamp":1702835664503,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"Xae73yfUjVVv","outputId":"ffb2ea0a-e7c0-4132-9c9e-1146da2cc8da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Path exists: /home/aazam/dev/Visual-Saliency-Prediction-UNET-Model/\n","Total Images in Dataset: 13426\n"]}],"source":["import os\n","import glob\n","\n","# Replace the \"home/username/dev/\" with your own directory path\n","work_dir= \"/home/aazam/dev\" + \"/Visual-Saliency-Prediction-UNET-Model/\"\n","# Verify image paths\n","if not os.path.exists(work_dir):\n","    print(f\"Path does not exist: {work_dir}\")\n","else:\n","    print(f\"Path exists: {work_dir}\")\n","\n","    # Create lists of image and mask file paths\n","    image_paths = glob.glob(work_dir + 'Dataset/Images/*.png')\n","    mask_paths = glob.glob(work_dir + 'Dataset/Masks/*.png')\n","    print('Total Images in Dataset:', len(image_paths))\n","\n","    # Misc Paths\n","    pretrain_modelpath = work_dir + \"Pre-trained_Model/\"\n","    logpath = work_dir + 'Logs'\n","    os.makedirs(pretrain_modelpath, exist_ok=True)\n","    os.makedirs(logpath, exist_ok=True)\n","\n","    # Create new name for Model which will be trained\n","    modelpath = pretrain_modelpath + 'unetmodel_v'+str(len(glob.glob(pretrain_modelpath + '/*.pth')))+'.pth'\n","\n","# Resizing images is optional, since dataset image size is 256x256x3\n","SIZE_X = 128\n","SIZE_Y = 128\n","n_classes = 1  # Number of classes for segmentation\n","# Define your parameters\n","batch_size = 32\n","epochs = 20\n","num_data = len(image_paths)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" # Indicates that TensorFlow's Keras API  will be used for training\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n","\n","import tensorflow as tf\n","from segmentation_models import Unet\n","from segmentation_models.losses import bce_jaccard_loss\n","from segmentation_models.metrics import iou_score\n","\n","# Restrict TensorFlow to only use the GPU\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Restrict TensorFlow to only use the first GPU\n","    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","    # Set a memory limit\n","    config = tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)\n","    tf.config.experimental.set_virtual_device_configuration(gpus[0], [config])\n","\n","  except RuntimeError as e:\n","    # Visible devices must be set before GPUs have been initialized\n","    print(e)\n","\n","# Define the dataset loading and preprocessing function\n","def preprocess_stage(image_path, mask_path):\n","    # Load and preprocess image\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, (SIZE_X, SIZE_Y))\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","\n","    # Load and preprocess mask\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    mask = tf.image.resize(mask, (SIZE_X, SIZE_Y))\n","    mask = tf.math.round(mask / 255.0)\n","\n","    return image, mask\n","\n","# Adopted U-Net model architecture from \"segmentation_models\" library\n","# Utilized ResNet34 as the backbone, used initial weights from pretrained network ImageNet (Transfer Learning)\n","def unet_model(input_shape):\n","    model = Unet(backbone_name='resnet34', input_shape=input_shape, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    model.compile(optimizer='adam', loss=bce_jaccard_loss, metrics=[iou_score])\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["**Step 2:** Prepare & Split datasets to three batches sets (Training Set, Validation Set & Testing Set)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Load Dataset and prepare for training:\n","Total Dataset Images: 13426 \n","Train Split Images (60%) : 8055 \n","Validate Split Images (20%) : 2685 \n","Test Split Images (20%) : 2686\n"]}],"source":["# Calculate the number of samples in each set\n","train_split = 0.6\n","validate_split = 0.2\n","test_split = 1-(train_split + validate_split)\n","\n","num_train = int(train_split * num_data)\n","num_valid = int(validate_split * num_data)\n","\n","# Convert your lists into TensorFlow Datasets\n","dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n","\n","# Shuffle the dataset\n","dataset = dataset.shuffle(len(image_paths), seed=42)\n","\n","# Split the dataset\n","dataset_train = dataset.take(num_train)\n","dataset_remaining = dataset.skip(num_train)\n","dataset_valid = dataset_remaining.take(num_valid)\n","dataset_test = dataset_remaining.skip(num_valid)\n","\n","print('Load Dataset and prepare for training:')\n","print(f\"Total Dataset Images: {num_data}\",\n","      f\"\\nTrain Split Images ({round(train_split*100)}%) : {len(dataset_train)}\",\n","      f\"\\nValidate Split Images ({round(validate_split*100)}%) : {len(dataset_valid)}\",\n","      f\"\\nTest Split Images ({round(test_split*100)}%) : {len(dataset_test)}\"\n","      )\n","\n","# Apply your loading and preprocessing function\n","dataset_train = dataset_train.map(preprocess_stage)\n","dataset_valid = dataset_valid.map(preprocess_stage)\n","dataset_test = dataset_test.map(preprocess_stage)\n","\n","# Batch the data\n","dataset_train = dataset_train.batch(batch_size)\n","dataset_valid = dataset_valid.batch(batch_size)\n","dataset_test = dataset_test.batch(batch_size)\n","\n","# Prefetch for performance\n","dataset_train = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n","dataset_valid = dataset_valid.prefetch(buffer_size=tf.data.AUTOTUNE)\n","dataset_test = dataset_test.prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["**Step 3:** Train & Validate the Unet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":797018,"status":"ok","timestamp":1702823042360,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"fuENlaI1jVVy","outputId":"0668de73-9f8a-4968-e25c-b92bd28d87cb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Define model\n","input_shape = (SIZE_X, SIZE_Y, 3)  # Adjust based on the size of your images\n","model = unet_model(input_shape)\n","\n","# Model Checkpoint - save model after every epochs\n","# Save Best only - latest best model will not be overwritten\n","checkpointer = tf.keras.callbacks.ModelCheckpoint(modelpath,verbose=1,save_best_only=True)\n","\n","# Early Stopping - TensorBoard Callbacks\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss'),\n","    tf.keras.callbacks.TensorBoard(log_dir= logpath),\n","    checkpointer\n","]\n","\n","# Train the model\n","history = model.fit(training_data = dataset_train, \n","                    validation_data = dataset_valid, \n","                    epochs = epochs, \n","                    callbacks = callbacks)\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['iou_score'], label='Training IoU')\n","plt.plot(history.history['val_iou_score'], label='Validation IoU')\n","plt.title('Training and Validation IoU')\n","plt.xlabel('Epoch')\n","plt.ylabel('IoU')\n","plt.legend()\n","# Plot training and validation loss\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","print(f\"Trained Model has been stored:\"{modelpath})"]},{"cell_type":"markdown","metadata":{"id":"tRRn_scQub2a"},"source":["**Step 4:** Evaluate the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5588,"status":"ok","timestamp":1702835694555,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"85fupNOXnlh4","outputId":"8e485cbe-1173-4b80-e4fe-d51b364c7c53"},"outputs":[],"source":["import os\n","from tensorflow import keras\n","from keras.models import load_model\n","from keras.utils import plot_model\n","# Directory containing your model files\n","model_directory = drive_dir + 'Trained Models/'\n","# List all files in the directory\n","model_files = [f for f in os.listdir(model_directory) if f.endswith(\".h5\")]\n","# Display the list of model files\n","print(\"Available model files:\")\n","for i, model_file in enumerate(model_files, start=1):\n","    print(f\"{i}. {model_file}\")\n","# Ask the user to select a model file\n","try:\n","    selected_index = int(input(\"\\nEnter the number corresponding to the model file you want to select: \")) - 1\n","    selected_model = model_files[selected_index]\n","    selected_model_path = os.path.join(model_directory, selected_model)\n","    print(f\"\\nSelected model: {selected_model_path}\")\n","except (ValueError, IndexError):\n","    print(\"Invalid selection. Please enter a valid number.\")\n","\n","# Load the Model\n","model = keras.models.load_model(selected_model_path, compile=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":24502,"status":"ok","timestamp":1702835945969,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"OMjAngEk0rTs","outputId":"93e8f80b-6d7d-4442-9483-b00d19ba5981"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# Function to create a mask from predicted values\n","def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask[0]\n","\n","rows = 5\n","dataset_samples = dataset_test\n","\n","# Set up the subplots\n","fig, axs = plt.subplots(rows, 3, figsize=(9, rows*3))\n","\n","for i, (image, mask, filepath) in enumerate(dataset_samples):\n","    # Assuming `model` is already defined and trained\n","    pred_mask = model.predict(image)\n","    pred_mask_np = create_mask(pred_mask).numpy()\n","\n","    image_path = filepath[0].numpy().decode('utf-8')\n","    # Load the image using PIL (Python Imaging Library)\n","    img = Image.open(image_path)\n","    target_size=(SIZE_X,SIZE_Y)\n","    # Resize the image\n","    img = img.resize(target_size)\n","    row = i % rows\n","    axs[row, 0].imshow(img)\n","    axs[row, 0].set_title(f'Image {i + 1}')\n","    axs[row, 0].axis('off')\n","    axs[row, 1].imshow(mask[0],cmap='gray')\n","    axs[row, 1].set_title('Ground Truth Mask')\n","    axs[row, 1].axis('off')\n","    axs[row, 2].imshow(pred_mask[0],cmap='gray')\n","    axs[row, 2].set_title('Predicted Mask')\n","    axs[row, 2].axis('off')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278048,"status":"ok","timestamp":1702832411604,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"n8jiGe08eqOH","outputId":"d34ff251-d37d-4b76-e217-48e938147cf6"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# Function to create a confusion matrix\n","def create_confusion_matrix(model, dataset):\n","    true_labels = []\n","    predicted_labels = []\n","    for images, masks, _ in dataset:\n","        # Get model predictions\n","        predictions = model.predict(images)\n","        # Append flattened masks and predictions to the lists\n","        true_labels.append(tf.reshape(masks, [-1]).numpy())\n","        predicted_labels.append(tf.reshape(predictions, [-1]).numpy())\n","    # Concatenate the lists to create NumPy arrays\n","    true_labels = np.concatenate(true_labels)\n","    predicted_labels = np.concatenate(predicted_labels)\n","    # Use vectorized operations to create confusion matrix\n","    threshold = 0.5\n","    true_labels_binary = (true_labels > threshold).astype(int)\n","    predicted_labels_binary = (predicted_labels > threshold).astype(int)\n","    cm = confusion_matrix(true_labels_binary, predicted_labels_binary)\n","    return cm\n","# Get confusion matrix for dataset_test\n","confusion_mat = create_confusion_matrix(model, dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"executionInfo":{"elapsed":1167,"status":"ok","timestamp":1702833635880,"user":{"displayName":"Ali Azam","userId":"11224395010900996548"},"user_tz":-300},"id":"PVf9XCJUiKck","outputId":"c6d0e17e-a683-4e8f-997c-1668f48f9202"},"outputs":[],"source":["# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n","# Extract true positives, true negatives, false positives, and false negatives from the confusion matrix\n","tn, fp, fn, tp = confusion_mat.ravel()\n","# Calculate metrics\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","precision = tp / (tp + fp) if (tp + fp) > 0 else 0  # To avoid division by zero\n","recall = tp / (tp + fn) if (tp + fn) > 0 else 0  # To avoid division by zero\n","f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # To avoid division by zero\n","print('\\nTrained Model Results:')\n","print(f\"Accuracy: {round(accuracy*100)}%\")\n","print(f\"Precision:  {round(precision*100)}%\")\n","print(f\"Recall:  {round(recall*100)}%\")\n","print(f\"F1 Score: {round(f1*100)}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
